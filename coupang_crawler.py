# coupang_crawler.py - ë””ë²„ê¹… ê°•í™” ë²„ì „
import time
import random
import urllib.parse
import re
import os
from datetime import datetime
from bs4 import BeautifulSoup
import logging
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class CoupangCrawler:
    def __init__(self, platform="pc", incog=True, delay=8, headless=True):
        self.platform = platform
        self.delay = delay
        self.driver = None
        self.incog = incog
        self.headless = headless
        self.ua = self._get_stable_ua()
        self.win = "1920,1080" if platform == "pc" else "412,915"
        self.screenshot_count = 0

    def _get_stable_ua(self):
        """ë” ì•ˆì •ì ì¸ User-Agent ë°˜í™˜"""
        if self.platform == "pc":
            return "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
        else:
            return "Mozilla/5.0 (Linux; Android 13; SM-G991B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Mobile Safari/537.36"

    def _opts(self):
        """ê°œì„ ëœ Chrome ì˜µì…˜"""
        options = Options()
        
        if self.incog:
            options.add_argument("--incognito")
        if self.headless:
            options.add_argument("--headless=new")
        
        # ê¸°ë³¸ ì˜µì…˜ë“¤
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-gpu")
        options.add_argument("--disable-extensions")
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_argument("--disable-web-security")
        options.add_argument("--ignore-certificate-errors")
        options.add_argument("--allow-running-insecure-content")
        
        # User-Agent ë° ì°½ í¬ê¸°
        options.add_argument(f"--user-agent={self.ua}")
        options.add_argument(f"--window-size={self.win}")
        
        # íƒì§€ ìš°íšŒ ì˜µì…˜
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        
        logger.info(f"ğŸ”§ Chrome ì˜µì…˜ ì„¤ì • ì™„ë£Œ - í”Œë«í¼: {self.platform}, í—¤ë“œë¦¬ìŠ¤: {self.headless}")
        
        return options

    def _build(self):
        """ê°œì„ ëœ ë“œë¼ì´ë²„ ë¹Œë“œ"""
        logger.info(f"ğŸš€ Chrome ë“œë¼ì´ë²„ ìƒì„± ì‹œì‘ - {self.platform}")
        try:
            options = self._opts()
            self.driver = webdriver.Chrome(options=options)
            
            # ì›¹ë“œë¼ì´ë²„ íƒì§€ ë°©ì§€ ìŠ¤í¬ë¦½íŠ¸
            logger.info("ğŸ›¡ï¸ ì›¹ë“œë¼ì´ë²„ íƒì§€ ë°©ì§€ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰")
            self.driver.execute_script(
                "Object.defineProperty(navigator,'webdriver',{get:() => undefined});"
            )
            self.driver.execute_script(
                "Object.defineProperty(navigator,'plugins',{get:() => [1, 2, 3, 4, 5]});"
            )
            
            # íƒ€ì„ì•„ì›ƒ ì„¤ì •
            self.driver.set_page_load_timeout(45)
            self.driver.implicitly_wait(10)
            
            logger.info("âœ… Chrome ë“œë¼ì´ë²„ ìƒì„± ì„±ê³µ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë“œë¼ì´ë²„ ìƒì„± ì‹¤íŒ¨: {e}")
            return False

    def _take_screenshot(self, filename_prefix="debug"):
        """ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜"""
        try:
            self.screenshot_count += 1
            timestamp = datetime.now().strftime("%H%M%S")
            filename = f"/tmp/{filename_prefix}_{self.platform}_{timestamp}_{self.screenshot_count}.png"
            
            self.driver.save_screenshot(filename)
            logger.info(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {filename}")
            return filename
        except Exception as e:
            logger.warning(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥ ì‹¤íŒ¨: {e}")
            return None

    def _load(self, url):
        """ê°œì„ ëœ í˜ì´ì§€ ë¡œë“œ - ìŠ¤í¬ë¦°ìƒ· í¬í•¨"""
        logger.info(f"ğŸŒ í˜ì´ì§€ ë¡œë“œ ì‹œì‘: {url}")
        
        for attempt in range(3):
            try:
                logger.info(f"ğŸ“¡ ì‹œë„ {attempt + 1}/3: í˜ì´ì§€ ìš”ì²­ ì¤‘...")
                self.driver.get(url)
                
                # í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ ëŒ€ê¸°
                logger.info("â³ í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ ëŒ€ê¸° ì¤‘...")
                WebDriverWait(self.driver, 20).until(
                    lambda driver: driver.execute_script("return document.readyState") == "complete"
                )
                
                # ë¡œë“œ í›„ ìŠ¤í¬ë¦°ìƒ·
                self._take_screenshot(f"loaded_page_{attempt}")
                
                # í˜ì´ì§€ ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
                try:
                    page_title = self.driver.title
                    current_url = self.driver.current_url
                    page_source_length = len(self.driver.page_source)
                    
                    logger.info(f"ğŸ“‹ í˜ì´ì§€ ì •ë³´:")
                    logger.info(f"   - ì œëª©: {page_title}")
                    logger.info(f"   - í˜„ì¬ URL: {current_url}")
                    logger.info(f"   - HTML í¬ê¸°: {page_source_length:,} bytes")
                    
                    # CAPTCHA ë˜ëŠ” ì°¨ë‹¨ í™•ì¸
                    page_text = self.driver.page_source.lower()
                    if any(keyword in page_text for keyword in ['captcha', 'ë¡œë´‡ì´ ì•„ë‹™ë‹ˆë‹¤', 'robot', 'verification']):
                        logger.error("ğŸš« CAPTCHA ë˜ëŠ” ì ‘ê·¼ ì œí•œ í˜ì´ì§€ ê°ì§€ë¨!")
                        self._take_screenshot(f"captcha_detected_{attempt}")
                        
                except Exception as e:
                    logger.warning(f"í˜ì´ì§€ ì •ë³´ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
                
                # ë”œë ˆì´ ì ìš©
                wait_time = random.uniform(self.delay, self.delay + 3)
                logger.info(f"ğŸ˜´ {wait_time:.1f}ì´ˆ ëŒ€ê¸° ì¤‘...")
                time.sleep(wait_time)
                
                # ìƒí’ˆ ë¡œë“œ ëŒ€ê¸°
                self._wait_for_products()
                
                logger.info("âœ… í˜ì´ì§€ ë¡œë“œ ì„±ê³µ")
                return True
                
            except Exception as e:
                logger.warning(f"âš ï¸ í˜ì´ì§€ ë¡œë“œ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
                if attempt < 2:
                    logger.info(f"ğŸ”„ 5ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(5)
                else:
                    logger.error("âŒ ëª¨ë“  í˜ì´ì§€ ë¡œë“œ ì‹œë„ ì‹¤íŒ¨")
                    
        return False

    def _wait_for_products(self):
        """ìƒí’ˆ ì¹´ë“œ ë¡œë“œ ëŒ€ê¸°"""
        logger.info("ğŸ›ï¸ ìƒí’ˆ ì¹´ë“œ ë¡œë“œ ëŒ€ê¸° ì¤‘...")
        
        try:
            if self.platform == "android":
                selectors = ["li.plp-default__item"]
            else:
                selectors = [
                    "li.ProductUnit_productUnit__Qd6sv",
                    "dl[data-product-id]",
                    "li.search-product",
                    "div.search-product"
                ]
            
            for i, selector in enumerate(selectors):
                try:
                    logger.info(f"ğŸ” ì„ íƒì {i+1}/{len(selectors)} ì‹œë„: {selector}")
                    WebDriverWait(self.driver, 10).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, selector))
                    )
                    logger.info(f"âœ… ìƒí’ˆ ì¹´ë“œ ë°œê²¬: {selector}")
                    return
                except:
                    logger.info(f"âŒ ì„ íƒì ì‹¤íŒ¨: {selector}")
                    continue
                    
            logger.warning("âš ï¸ ëª¨ë“  ì„ íƒìë¡œ ìƒí’ˆ ì¹´ë“œë¥¼ ì°¾ì§€ ëª»í•¨")
            
        except Exception as e:
            logger.warning(f"ìƒí’ˆ ë¡œë“œ ëŒ€ê¸° ì¤‘ ì˜¤ë¥˜: {e}")

    def rank(self, kw, tgt_url, pages=5):
        """ê°œì„ ëœ ìˆœìœ„ ê²€ìƒ‰ - ë””ë²„ê¹… ê°•í™” ë²„ì „"""
        logger.info("="*60)
        logger.info(f"ğŸš€ í¬ë¡¤ë§ ì‹œì‘")
        logger.info(f"   - í‚¤ì›Œë“œ: {kw}")
        logger.info(f"   - í”Œë«í¼: {self.platform}")
        logger.info(f"   - ëŒ€ìƒ URL: {tgt_url}")
        logger.info(f"   - ê²€ìƒ‰ í˜ì´ì§€: {pages}")
        logger.info("="*60)
        
        if not self._build():
            logger.error("âŒ ë“œë¼ì´ë²„ ë¹Œë“œ ì‹¤íŒ¨")
            return None
        
        try:
            # URLì—ì„œ ID ì¶”ì¶œ
            prod, item, vend = self._ids(tgt_url)
            logger.info(f"ğŸ†” ì¶”ì¶œëœ ID:")
            logger.info(f"   - Product ID: {prod}")
            logger.info(f"   - Item ID: {item}")
            logger.info(f"   - Vendor Item ID: {vend}")
            
            # ê²€ìƒ‰ URL ë² ì´ìŠ¤ ì„¤ì •
            if self.platform == "android":
                base = "https://m.coupang.com/nm/search?q="
                logger.info("ğŸ“± ëª¨ë°”ì¼ ê²€ìƒ‰ ëª¨ë“œ")
            else:
                base = "https://www.coupang.com/np/search?q="
                logger.info("ğŸ’» PC ê²€ìƒ‰ ëª¨ë“œ")
            
            # í˜ì´ì§€ë³„ ê²€ìƒ‰
            for p in range(1, pages + 1):
                logger.info(f"\nğŸ“„ í˜ì´ì§€ {p}/{pages} ê²€ìƒ‰ ì‹œì‘")
                logger.info("-" * 40)
                
                url = f"{base}{urllib.parse.quote(kw)}&page={p}"
                logger.info(f"ğŸ”— ê²€ìƒ‰ URL: {url}")
                
                if not self._load(url):
                    logger.warning(f"âš ï¸ í˜ì´ì§€ {p} ë¡œë“œ ì‹¤íŒ¨ - ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™")
                    continue
                
                # HTML íŒŒì‹±
                soup = BeautifulSoup(self.driver.page_source, "html.parser")
                
                # ìƒí’ˆ ì¹´ë“œ ì°¾ê¸°
                cards = self._find_product_cards(soup, p)
                
                if not cards:
                    logger.warning(f"âŒ í˜ì´ì§€ {p}ì—ì„œ ìƒí’ˆ ì¹´ë“œë¥¼ ì°¾ì§€ ëª»í•¨")
                    
                    # ë””ë²„ê¹… ì •ë³´ ìˆ˜ì§‘
                    page_text = soup.get_text()
                    logger.info(f"ğŸ“ í˜ì´ì§€ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(page_text)}")
                    
                    # í‚¤ì›Œë“œê°€ í˜ì´ì§€ì— ìˆëŠ”ì§€ í™•ì¸
                    if kw.lower() in page_text.lower():
                        logger.info(f"âœ… í‚¤ì›Œë“œ '{kw}' í˜ì´ì§€ì—ì„œ ë°œê²¬ë¨")
                    else:
                        logger.warning(f"âŒ í‚¤ì›Œë“œ '{kw}' í˜ì´ì§€ì—ì„œ ë°œê²¬ë˜ì§€ ì•ŠìŒ")
                    
                    # í˜ì´ì§€ ìƒ˜í”Œ í…ìŠ¤íŠ¸ ë¡œê¹…
                    sample_text = page_text[:1000].replace('\n', ' ').strip()
                    logger.info(f"ğŸ“„ í˜ì´ì§€ ë‚´ìš© ìƒ˜í”Œ: {sample_text}")
                    
                    # ìŠ¤í¬ë¦°ìƒ· ì €ì¥
                    self._take_screenshot(f"no_products_page_{p}")
                    continue
                
                # ìˆœìœ„ ê³„ì‚°
                result = self._calculate_rank(cards, kw, p, prod, item, vend)
                if result:
                    logger.info(f"ğŸ¯ ìˆœìœ„ ë°œê²¬!")
                    logger.info(f"   - ìˆœìœ„: {result['rank']}ìœ„")
                    logger.info(f"   - í˜ì´ì§€: {result['page']}")
                    logger.info(f"   - ìƒí’ˆëª…: {result['product']}")
                    
                    # ì„±ê³µ ìŠ¤í¬ë¦°ìƒ·
                    self._take_screenshot(f"found_rank_{result['rank']}")
                    
                    self.driver.quit()
                    return result
                else:
                    logger.info(f"âŒ í˜ì´ì§€ {p}ì—ì„œ ëŒ€ìƒ ìƒí’ˆ ë¯¸ë°œê²¬")
            
            logger.info("ğŸ” ëª¨ë“  í˜ì´ì§€ ê²€ìƒ‰ ì™„ë£Œ - ëŒ€ìƒ ìƒí’ˆì„ ì°¾ì§€ ëª»í•¨")
            self.driver.quit()
            return None
            
        except Exception as e:
            logger.error(f"ğŸ’¥ í¬ë¡¤ë§ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            logger.exception("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
            
            # ì˜¤ë¥˜ ìŠ¤í¬ë¦°ìƒ·
            self._take_screenshot("error_occurred")
            
            if self.driver:
                self.driver.quit()
            return None

    def _find_product_cards(self, soup, page_num):
        """í”Œë«í¼ë³„ ìƒí’ˆ ì¹´ë“œ ì°¾ê¸° - ë””ë²„ê¹… ê°•í™”"""
        logger.info(f"ğŸ” í˜ì´ì§€ {page_num}ì—ì„œ ìƒí’ˆ ì¹´ë“œ ê²€ìƒ‰ ì¤‘...")
        
        if self.platform == "android":
            selectors = [
                "li.plp-default__item",
                ".search-product-item",
                "[data-product-id]",
                ".product-item"
            ]
        else:
            selectors = [
                "li.ProductUnit_productUnit__Qd6sv",
                "dl[data-product-id]",
                "li.search-product",
                "div.search-product",
                "li[data-product-id]",
                "div[data-product-id]",
                ".search-product-wrap",
                ".product-item"
            ]
        
        for i, selector in enumerate(selectors):
            logger.info(f"ğŸ¯ ì„ íƒì {i+1}/{len(selectors)} ì‹œë„: {selector}")
            cards = soup.select(selector)
            
            if cards:
                logger.info(f"âœ… '{selector}' ì„ íƒìë¡œ {len(cards)}ê°œ ìƒí’ˆ ì¹´ë“œ ë°œê²¬")
                
                # ê° ì¹´ë“œì˜ ê¸°ë³¸ ì •ë³´ ë¡œê¹…
                for j, card in enumerate(cards[:3]):  # ì²˜ìŒ 3ê°œë§Œ ìƒ˜í”Œë§
                    card_text = card.get_text(strip=True)[:100]
                    logger.info(f"   ğŸ“¦ ì¹´ë“œ {j+1}: {card_text}...")
                
                return cards
            else:
                logger.info(f"âŒ '{selector}' ì„ íƒìë¡œ ìƒí’ˆ ì¹´ë“œ ì—†ìŒ")
        
        logger.warning("âš ï¸ ëª¨ë“  ì„ íƒìë¡œ ìƒí’ˆ ì¹´ë“œë¥¼ ì°¾ì§€ ëª»í•¨")
        return []

    def _calculate_rank(self, cards, kw, page, prod, item, vend):
        """ìˆœìœ„ ê³„ì‚° - ë””ë²„ê¹… ê°•í™”"""
        logger.info(f"ğŸ§® ìˆœìœ„ ê³„ì‚° ì‹œì‘ - {len(cards)}ê°œ ì¹´ë“œ ë¶„ì„")
        
        idx = 0
        ad_count = 0
        
        for card_num, c in enumerate(cards, 1):
            logger.info(f"ğŸ” ì¹´ë“œ {card_num}/{len(cards)} ë¶„ì„ ì¤‘...")
            
            # ê´‘ê³  í•„í„°ë§
            ad_indicators = [
                "span.ad-badge", 
                "div.AdMark_adMark__KPMsC",
                ".ad-product",
                "[data-ad-id]",
                ".sponsored",
                ".ad-label",
                "[data-impression-id]"
            ]
            
            is_ad = any(c.select_one(indicator) for indicator in ad_indicators)
            if is_ad:
                ad_count += 1
                logger.info(f"   ğŸ“¢ ê´‘ê³  ìƒí’ˆ - ìˆœìœ„ì—ì„œ ì œì™¸ (ê´‘ê³  {ad_count}ê°œ)")
                continue
            
            idx += 1
            logger.info(f"   ğŸ† ìˆœìœ„ {idx}: ì¼ë°˜ ìƒí’ˆ")
            
            # ìƒí’ˆ ID ì¶”ì¶œ
            ids = self._extract_product_ids(c)
            logger.info(f"   ğŸ†” ì¶”ì¶œëœ ID - Product: {ids['product_id']}, Item: {ids['item_id']}, Vendor: {ids['vendor_id']}")
            
            # ë§¤ì¹­ í™•ì¸
            if self._is_match(ids, prod, item, vend):
                logger.info(f"   ğŸ¯ ëŒ€ìƒ ìƒí’ˆ ë§¤ì¹­ ì„±ê³µ!")
                
                name_txt = self._extract_product_name(c)
                logger.info(f"   ğŸ“¦ ìƒí’ˆëª…: {name_txt}")
                
                result = {
                    "keyword": kw,
                    "platform": self.platform,
                    "rank": idx,
                    "page": page,
                    "product": name_txt,
                    "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                }
                
                return result
            else:
                logger.info(f"   âŒ ëŒ€ìƒ ìƒí’ˆ ë¶ˆì¼ì¹˜")
        
        logger.info(f"ğŸ“Š í˜ì´ì§€ {page} ë¶„ì„ ì™„ë£Œ - ì´ {idx}ê°œ ì¼ë°˜ ìƒí’ˆ, {ad_count}ê°œ ê´‘ê³  ìƒí’ˆ")
        return None

    def _extract_product_ids(self, card):
        """ìƒí’ˆ IDë“¤ ì¶”ì¶œ"""
        ids = {
            'product_id': card.get("data-product-id", ""),
            'item_id': card.get("data-item-id", ""),
            'vendor_id': card.get("data-vendor-item-id", card.get("data-id", ""))
        }
        
        # ë§í¬ì—ì„œë„ ID ì¶”ì¶œ
        link = card.find("a", href=True)
        if link and link.get("href"):
            href = link["href"]
            
            prod_match = re.search(r"/products/(\d+)", href)
            item_match = re.search(r"itemId=(\d+)", href)
            vendor_match = re.search(r"vendorItemId=(\d+)", href)
            
            if not ids['product_id'] and prod_match:
                ids['product_id'] = prod_match.group(1)
            if not ids['item_id'] and item_match:
                ids['item_id'] = item_match.group(1)
            if not ids['vendor_id'] and vendor_match:
                ids['vendor_id'] = vendor_match.group(1)
        
        return ids

    def _is_match(self, ids, prod, item, vend):
        """ID ë§¤ì¹­ í™•ì¸"""
        match_vendor = ids['vendor_id'] == vend and vend != ""
        match_item = ids['item_id'] == item and item != ""
        match_product = ids['product_id'] == prod and prod != ""
        
        if match_vendor:
            logger.info(f"   âœ… Vendor ID ë§¤ì¹­: {vend}")
        if match_item:
            logger.info(f"   âœ… Item ID ë§¤ì¹­: {item}")
        if match_product:
            logger.info(f"   âœ… Product ID ë§¤ì¹­: {prod}")
        
        return match_vendor or match_item or match_product

    def _extract_product_name(self, card):
        """ìƒí’ˆëª… ì¶”ì¶œ"""
        if self.platform == "android":
            selectors = [
                "strong.title",
                ".prod-name",
                ".title",
                ".product-title"
            ]
        else:
            selectors = [
                ".ProductUnit_productName__gre7e",
                "div.name",
                ".prod-name",
                "div[data-product-name]",
                "a.prod-link div.name",
                ".search-product-wrap .descriptions .name",
                ".search-product-wrap .name",
                ".product-name",
                ".product-title"
            ]
        
        for selector in selectors:
            element = card.select_one(selector)
            if element:
                name = element.get_text(strip=True)
                logger.info(f"   ğŸ“ ìƒí’ˆëª… ì¶”ì¶œ ì„±ê³µ (ì„ íƒì: {selector})")
                return name
        
        logger.warning(f"   âš ï¸ ìƒí’ˆëª… ì¶”ì¶œ ì‹¤íŒ¨ - ëª¨ë“  ì„ íƒì ì‹¤íŒ¨")
        return "ìƒí’ˆëª… ì¶”ì¶œ ì‹¤íŒ¨"

    @staticmethod
    def _ids(url):
        """URLì—ì„œ ìƒí’ˆ ID ì¶”ì¶œ"""
        p = urllib.parse.urlparse(url)
        q = urllib.parse.parse_qs(p.query)
        
        prod = next((x for x in p.path.split('/') if x.isdigit()), "")
        item_id = q.get("itemId", [""])[0]
        vendor_item_id = q.get("vendorItemId", [""])[0]
        
        return prod, item_id, vendor_item_id

    def __del__(self):
        if hasattr(self, 'driver') and self.driver:
            try:
                self.driver.quit()
            except:
                pass
